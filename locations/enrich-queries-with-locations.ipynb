{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysolr\n",
    "import spacy\n",
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "import dateutil.parser\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a request to the Mapquest service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MapQuest Geocode service.  More info: https://developer.mapquest.com/documentation/geocoding-api/\n",
    "mapquest_url='https://www.mapquestapi.com/geocoding/v1/address?key=AuqdPFEWYhm7rZRN5hX5HeWSKgaO2u7d&location='\n",
    "def mapquest(text):\n",
    "    req = requests.get(mapquest_url+text)\n",
    "    jsn = req.json()\n",
    "    loc = jsn[\"results\"][0][\"locations\"][0]\n",
    "    return loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#us-map-with-latitude-longitude-united-states-latitude-longitude.jpg\n",
    "def near(loc):\n",
    "    latlng = loc[\"latLng\"]\n",
    "    return round(latlng[\"lat\"]),round(latlng[\"lng\"])\n",
    "\n",
    "def norm(loc):\n",
    "    loctypes = {\"City\":\"adminArea4\",\"County\":\"adminArea3\",\"State\":\"adminArea2\",\"Country\":\"adminArea1\"}\n",
    "    location = None\n",
    "    for fld in loctypes:\n",
    "        if len(loc[fld]) and not location:\n",
    "            location = loc[fld]\n",
    "    return location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a couple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, -79)\n",
      "(36, -79)\n",
      "(36, -79)\n",
      "(36, -79)\n",
      "(43, -78)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n(36, -79)\\n(36, -79)\\n(36, -79)\\n(36, -79)\\n(43, -78)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(near(mapquest(\"Raleigh, NC\")))\n",
    "print(near(mapquest(\"Raleigh\")))\n",
    "print(near(mapquest(\"Chapel Hill\")))\n",
    "print(near(mapquest(\"Durham\")))\n",
    "print(near(mapquest(\"Rochester\")))\n",
    "'''\n",
    "(36, -79)\n",
    "(36, -79)\n",
    "(36, -79)\n",
    "(36, -79)\n",
    "(43, -78)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get entities with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_location(text):\n",
    "    doc = nlp(text)\n",
    "    locs = []\n",
    "    for gpe in filter(lambda w: w.ent_type_ in ['GPE','LOC'], doc):\n",
    "        print(\"Text:\",text,\"\\t|\\tLocation:\",gpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recognize_entities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b7435d1df257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrecognize_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Kevin alone in NYC\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrecognize_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Indiana Jones in India\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrecognize_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"action hero movie in LA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrecognize_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Boxing Revenge in Moscow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'recognize_entities' is not defined"
     ]
    }
   ],
   "source": [
    "recognize_entities(\"Kevin alone in NYC\")\n",
    "recognize_entities(\"Indiana Jones in India\")\n",
    "recognize_entities(\"action hero movie in LA\")\n",
    "recognize_entities(\"Boxing Revenge in Moscow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recognizing location entities with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_location_entities(text):\n",
    "    #debug here:\n",
    "    # https://explosion.ai/demos/displacy?text=Kevin%20McAllister%20in%20New%20York%20NY&model=en_core_web_lg&cpu=1&cph=1\n",
    "    # merge entities and noun chunks into one token\n",
    "    doc = nlp(text)\n",
    "    spans = list(doc.ents)# + list(doc.noun_chunks)\n",
    "    for span in spans:\n",
    "        span.merge()\n",
    "\n",
    "    relations = []\n",
    "    for gpe in filter(lambda w: w.ent_type_ in ['GPE','LOC'], doc):\n",
    "        if gpe.dep_ in ('attr', 'dobj'):\n",
    "            subject = [w for w in gpe.head.lefts if w.dep_ == 'nsubj']\n",
    "            if subject:\n",
    "                subject = subject[0]\n",
    "                relations.append((subject, gpe))\n",
    "        elif gpe.dep_ == 'pobj' and gpe.head.dep_ == 'prep':\n",
    "            relations.append((gpe.head.head, gpe))\n",
    "        else:\n",
    "            relations.append((None,gpe))\n",
    "\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Kevin McAllister, New York NY)]\n",
      "[(alone, NYC)]\n",
      "[(Indiana Jones, india)]\n",
      "[(None, California)]\n",
      "[(revenge, moscow)]\n"
     ]
    }
   ],
   "source": [
    "print(extract_location_entities(\"Kevin McAllister in New York NY\"))\n",
    "print(extract_location_entities(\"Kevin alone in NYC\"))\n",
    "print(extract_location_entities(\"Indiana Jones in india\"))\n",
    "print(extract_location_entities(\"California action hero\"))\n",
    "print(extract_location_entities(\"boxing revenge in moscow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich a query with a location using SpaCy and Mapquest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_query_location(q):\n",
    "    \n",
    "    entities = duckling(q)\n",
    "    enrichment = {\"q\":q}\n",
    "    query = \"\"\n",
    "    cursor = 0\n",
    "    for e in entities:\n",
    "        dim = e[\"dim\"]\n",
    "        val = e[\"value\"]\n",
    "        typ = val[\"type\"]\n",
    "        if dim==\"time\" and typ==\"interval\":\n",
    "\n",
    "            values = val[\"values\"]\n",
    "\n",
    "            #Remove the interval text from the query\n",
    "            query += q[cursor:e[\"start\"]]\n",
    "            query += q[e[\"end\"]:]\n",
    "            cursor = e[\"end\"]\n",
    "\n",
    "            #Add the filter, convert to q and fq solr queries\n",
    "            fromdt = solrdate(values[0][\"from\"][\"value\"])\n",
    "            todt = solrdate(values[0][\"to\"][\"value\"])\n",
    "            enrichment[\"fq\"] = \"release_date:[\" + fromdt + \" TO \" + todt + \"]\"\n",
    "            enrichment[\"q\"]=query\n",
    "            \n",
    "    return enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solr Client\n",
    "solr = pysolr.Solr('http://localhost:8983/solr/tmdb')\n",
    "\n",
    "#Print the Title, Release Date, and Overview from TMDB\n",
    "def printresults(res):\n",
    "    for r in res:\n",
    "        print('\\n---')\n",
    "        print('\\n\\t'.join([r[\"title\"][0],r[\"release_date\"],r[\"overview\"][0]]))\n",
    "\n",
    "def solrquery(q):\n",
    "    return \"title_en:(\"+q+\")^1.2 overview_en:(\"+q+\")\"\n",
    "        \n",
    "#Enrich and Search a text query\n",
    "def search(query):\n",
    "    enriched = enrich_date_interval(query)\n",
    "    q = solrquery(enriched[\"q\"])\n",
    "    print(\"Searching for `\" + query + \"` ...\")\n",
    "    print(\"  q = \" + q)\n",
    "    if \"fq\" in enriched and isinstance(enriched[\"fq\"], str):\n",
    "        print(\"  fq = \" + enriched[\"fq\"])\n",
    "        res = solr.search(q=q,fq=enriched[\"fq\"],fl=\"title,overview,release_date\",rows=3)\n",
    "    else:\n",
    "        print(\"  ...no enrichments\")\n",
    "        res = solr.search(q=q,fl=\"title,overview,release_date\",rows=3)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try it with some good examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'printresults' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aef963d90df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprintresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"harry potter last 5 years\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'printresults' is not defined"
     ]
    }
   ],
   "source": [
    "printresults(search(\"harry potter last 5 years\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for `indiana jones 1/1/1980 to 12/31/1987` ...\n",
      "  q = title_en:(indiana jones )^1.2 overview_en:(indiana jones )\n",
      "  fq = release_date:[1980-01-01T00:00:00Z TO 1988-01-01T00:00:00Z]\n",
      "\n",
      "---\n",
      "Indiana Jones and the Temple of Doom\n",
      "\t1984-05-23T00:00:00Z\n",
      "\tAfter arriving in India, Indiana Jones is asked by a desperate village to find a mystical stone. He agrees – and stumbles upon a secret cult plotting a terrible plan in the catacombs of an ancient palace.\n",
      "\n",
      "---\n",
      "Raiders of the Lost Ark\n",
      "\t1981-06-12T00:00:00Z\n",
      "\tWhen Dr. Indiana Jones – the tweed-suited professor who just happens to be a celebrated archaeologist – is hired by the government to locate the legendary Ark of the Covenant, he finds himself up against the entire Nazi regime.\n",
      "\n",
      "---\n",
      "Guyana Tragedy: The Story of Jim Jones\n",
      "\t1980-04-15T00:00:00Z\n",
      "\tThe story of the Peoples Temple cult led by Jim Jones and the events leading up to one of the largest mass suicides in history.\n"
     ]
    }
   ],
   "source": [
    "printresults(search(\"indiana jones 1/1/1980 to 12/31/1987\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for `harry potter goblet` ...\n",
      "  q = title_en:(harry potter goblet)^1.2 overview_en:(harry potter goblet)\n",
      "  ...no enrichments\n",
      "\n",
      "---\n",
      "Harry Potter and the Goblet of Fire\n",
      "\t2005-11-05T00:00:00Z\n",
      "\tHarry starts his fourth year at Hogwarts, competes in the treacherous Triwizard Tournament and faces the evil Lord Voldemort. Ron and Hermione help Harry manage the pressure – but Voldemort lurks, awaiting his chance to destroy Harry and all that he stands for.\n",
      "\n",
      "---\n",
      "Harry Potter and the Philosopher's Stone\n",
      "\t2001-11-16T00:00:00Z\n",
      "\tHarry Potter has lived under the stairs at his aunt and uncle's house his whole life. But on his 11th birthday, he learns he's a powerful wizard -- with a place waiting for him at the Hogwarts School of Witchcraft and Wizardry. As he learns to harness his newfound powers with the help of the school's kindly headmaster, Harry uncovers the truth about his parents' deaths -- and about the villain who's to blame.\n",
      "\n",
      "---\n",
      "A Very Potter Musical\n",
      "\t2009-04-09T00:00:00Z\n",
      "\tIn April 2009, a group of University of Michigan students (Team StarKid) performed what was renamed \"A Very Potter Musical\", a two act musical parody that featured major elements from all seven Harry Potter books and an original score.\n"
     ]
    }
   ],
   "source": [
    "printresults(search(\"harry potter goblet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
