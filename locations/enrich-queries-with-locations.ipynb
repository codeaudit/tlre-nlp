{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a request to the Mapquest service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MapQuest Geocode service.  More info: https://developer.mapquest.com/documentation/geocoding-api/\n",
    "mapquest_url='https://www.mapquestapi.com/geocoding/v1/address?key=FVfj6GGCXVEGUjXvokn4IbXdNAHIbbH0&location='\n",
    "def geocode(text):\n",
    "    req = requests.get(mapquest_url+text)\n",
    "    jsn = req.json()\n",
    "    loc = jsn[\"results\"][0][\"locations\"][0]\n",
    "    return loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#us-map-with-latitude-longitude-united-states-latitude-longitude.jpg\n",
    "\n",
    "#Disambiguate to the nearest lat/lng whole numbers:\n",
    "def near(loc):\n",
    "    latlng = loc[\"latLng\"]\n",
    "    return round(latlng[\"lat\"]),round(latlng[\"lng\"])\n",
    "\n",
    "#Normalize to City|State|Country:\n",
    "def norm(loc):\n",
    "    loctypes = {\"City\":\"\",\"State\":\"\",\"Country\":\"\"}\n",
    "    location = None\n",
    "    for i in range(8):\n",
    "        aai = \"adminArea\"+str(i)\n",
    "        aat = aai+\"Type\"\n",
    "        if aat in loc.keys() and loc[aat] in loctypes.keys():\n",
    "            loctypes[loc[aat]] = aai\n",
    "    for typ in loctypes.keys():\n",
    "        fld = loctypes[typ]\n",
    "        if fld in loc.keys() and len(loc[fld]):\n",
    "            if not location:\n",
    "                location = loc[fld]\n",
    "            else:\n",
    "                location += \"|\" + loc[fld]\n",
    "    if not location:\n",
    "        location = \"_UNKNOWN_\"\n",
    "    return location.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a couple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raleigh|NC|US\n",
      "Raleigh|NC|US\n",
      "Chapel_Hill|NC|US\n",
      "Durham|NC|US\n",
      "Durham|NC|US\n",
      "Charlotte|NC|US\n",
      "Bangkok|TH\n"
     ]
    }
   ],
   "source": [
    "#Normalize to City|State|Country\n",
    "print(norm(geocode(\"Raleigh, NC\")))\n",
    "print(norm(geocode(\"Raleigh\")))\n",
    "print(norm(geocode(\"Chapel Hill\")))\n",
    "print(norm(geocode(\"Durham\")))\n",
    "print(norm(geocode(\"RTP, NC\")))\n",
    "print(norm(geocode(\"Charlotte, NC\")))\n",
    "print(norm(geocode(\"Bangkok\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, -79)\n",
      "(36, -79)\n",
      "(36, -79)\n",
      "(36, -79)\n",
      "(36, -79)\n",
      "(35, -81)\n",
      "(14, 100)\n"
     ]
    }
   ],
   "source": [
    "print(near(geocode(\"Raleigh, NC\")))\n",
    "print(near(geocode(\"Raleigh\")))\n",
    "print(near(geocode(\"Chapel Hill\")))\n",
    "print(near(geocode(\"Durham\")))\n",
    "print(near(geocode(\"RTP, NC\")))\n",
    "#(36, -79)\n",
    "\n",
    "print(near(geocode(\"Charlotte, NC\")))\n",
    "#(35, -81)\n",
    "\n",
    "print(near(geocode(\"Bangkok\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity spans with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_independent_locations(text):\n",
    "    doc = nlp(text)\n",
    "    locs = []\n",
    "    #Fun fact, \"GPE\" means Geo-Political Entity\n",
    "    for gpe in filter(lambda w: w.ent_type_ in ['GPE','LOC'], doc):\n",
    "        print(\"Text:\",text,\"\\t|\\tLocation:\",gpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Kevin alone in NYC \t|\tLocation: NYC\n",
      "Text: Indiana Jones in India \t|\tLocation: India\n",
      "Text: action hero movie in LA \t|\tLocation: LA\n",
      "Text: Boxing Revenge in Moscow \t|\tLocation: Moscow\n"
     ]
    }
   ],
   "source": [
    "extract_independent_locations(\"Kevin alone in NYC\")\n",
    "extract_independent_locations(\"Indiana Jones in India\")\n",
    "extract_independent_locations(\"action hero movie in LA\")\n",
    "extract_independent_locations(\"Boxing Revenge in Moscow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject/Object dependency examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dependent_locations(text):\n",
    "    #debug here:\n",
    "    # https://explosion.ai/demos/displacy?text=Kevin%20McCallister%20in%20New%20York%20NY&model=en_core_web_lg&cpu=1&cph=1\n",
    "\n",
    "    #merge entities and noun chunks into one token\n",
    "    doc = nlp(text)\n",
    "    spans = list(doc.ents)# + list(doc.noun_chunks)\n",
    "    for span in spans:\n",
    "        span.merge()\n",
    "\n",
    "    relations = []\n",
    "    for gpe in filter(lambda w: w.ent_type_ in ['GPE','LOC'], doc):\n",
    "        if gpe.dep_ in ('attr', 'dobj'):\n",
    "            subject = [w for w in gpe.head.lefts if w.dep_ == 'nsubj']\n",
    "            if subject:\n",
    "                subject = subject[0]\n",
    "                relations.append((subject, gpe))\n",
    "        elif gpe.dep_ == 'pobj' and gpe.head.dep_ == 'prep':\n",
    "            relations.append((gpe.head.head, gpe))\n",
    "        else:\n",
    "            relations.append((None,gpe))\n",
    "\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Kevin McCallister, New York NY)]\n",
      "[(alone, NYC)]\n",
      "[(Indiana Jones, India)]\n",
      "[(None, California)]\n",
      "[(revenge, moscow)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(extract_dependent_locations(\"Kevin McCallister in New York NY\"))\n",
    "print(extract_dependent_locations(\"Kevin alone in NYC\"))\n",
    "print(extract_dependent_locations(\"Indiana Jones in India\"))\n",
    "print(extract_dependent_locations(\"California action hero\"))\n",
    "print(extract_dependent_locations(\"boxing revenge in moscow\"))\n",
    "print(extract_dependent_locations(\"Riddick in the underverse\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Machine GPE chunk examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chunked_locations(text):\n",
    "    #Use a basic finite state machine to chunk proper noun GPEs as one location\n",
    "    doc = nlp(text)\n",
    "    gpes = []\n",
    "    for s in doc.sents:\n",
    "        curr = []\n",
    "        isgpe = False\n",
    "        for t in s:\n",
    "            if (t.pos_ == 'PROPN' and t.ent_type_ == 'GPE') or (isgpe == True and t.text==','):\n",
    "                isgpe = True\n",
    "                if t.text!=',':\n",
    "                    curr.append(t.text)\n",
    "            elif isgpe == True:\n",
    "                gpes.append(' '.join(curr))\n",
    "                curr = []\n",
    "                isgpe = False\n",
    "            else:\n",
    "                isgpe = False\n",
    "        if(len(curr)):\n",
    "            gpes.append(' '.join(curr))\n",
    "            curr = []\n",
    "            isgpe = False\n",
    "    return gpes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New York NY']\n",
      "['NYC']\n",
      "['India']\n",
      "['California']\n",
      "[]\n",
      "['Moscow']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(extract_chunked_locations(\"Kevin McCallister in New York NY\"))\n",
    "print(extract_chunked_locations(\"Kevin alone in NYC\"))\n",
    "print(extract_chunked_locations(\"Indiana Jones in India\"))\n",
    "print(extract_chunked_locations(\"California action hero\"))\n",
    "print(extract_chunked_locations(\"boxing revenge in moscow\"))\n",
    "print(extract_chunked_locations(\"boxing revenge in Moscow\"))\n",
    "print(extract_chunked_locations(\"Riddick in the underverse\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich a query with a location using SpaCy and Mapquest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q': 'Kevin alone in ', 'fq': 'lat:41 lng:-74'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def enrich_query_location(q):\n",
    "    enrichment = {\"q\":q}\n",
    "    entities = extract_dependent_locations(q)\n",
    "    if len(entities) and len(entities[0])==2:\n",
    "        #found a location - look it up in mapquest and disambiguate\n",
    "        entity = entities[0][1].text\n",
    "        latlng = near(geocode(entity))\n",
    "        if latlng and len(latlng)==2:\n",
    "            # It's a valid location! \n",
    "            # ...add the filter query and remove the text from the query:\n",
    "            fq = \"lat:\"+str(latlng[0]) + \" lng:\"+str(latlng[1])\n",
    "            enrichment[\"fq\"] = fq\n",
    "            enrichment[\"q\"] = q.replace(entity,\"\")\n",
    "    return enrichment\n",
    "enrich_query_location(\"Kevin alone in NYC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
