{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysolr\n",
    "import spacy\n",
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "import dateutil.parser\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a request to the Mapquest service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.mapquestapi.com/geocoding/v1/batch?key=AuqdPFEWYhm7rZRN5hX5HeWSKgaO2u7d&maxResults=1&thumbMaps=false&location=New York&location=Manhattan&location=Thailand\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{123: [{'street': '',\n",
       "   'adminArea6': '',\n",
       "   'adminArea6Type': 'Neighborhood',\n",
       "   'adminArea5': 'New York',\n",
       "   'adminArea5Type': 'City',\n",
       "   'adminArea4': 'New York County',\n",
       "   'adminArea4Type': 'County',\n",
       "   'adminArea3': 'NY',\n",
       "   'adminArea3Type': 'State',\n",
       "   'adminArea1': 'US',\n",
       "   'adminArea1Type': 'Country',\n",
       "   'postalCode': '',\n",
       "   'geocodeQualityCode': 'A5XAX',\n",
       "   'geocodeQuality': 'CITY',\n",
       "   'dragPoint': False,\n",
       "   'sideOfStreet': 'N',\n",
       "   'linkId': '282040974',\n",
       "   'unknownInput': '',\n",
       "   'type': 's',\n",
       "   'latLng': {'lat': 40.713054, 'lng': -74.007228},\n",
       "   'displayLatLng': {'lat': 40.713054, 'lng': -74.007228}},\n",
       "  {'street': '',\n",
       "   'adminArea6': '',\n",
       "   'adminArea6Type': 'Neighborhood',\n",
       "   'adminArea5': 'Manhattan',\n",
       "   'adminArea5Type': 'City',\n",
       "   'adminArea4': 'New York County',\n",
       "   'adminArea4Type': 'County',\n",
       "   'adminArea3': 'NY',\n",
       "   'adminArea3Type': 'State',\n",
       "   'adminArea1': 'US',\n",
       "   'adminArea1Type': 'Country',\n",
       "   'postalCode': '',\n",
       "   'geocodeQualityCode': 'A5XAX',\n",
       "   'geocodeQuality': 'CITY',\n",
       "   'dragPoint': False,\n",
       "   'sideOfStreet': 'N',\n",
       "   'linkId': '282931599',\n",
       "   'unknownInput': '',\n",
       "   'type': 's',\n",
       "   'latLng': {'lat': 40.753259, 'lng': -74.003804},\n",
       "   'displayLatLng': {'lat': 40.753259, 'lng': -74.003804}},\n",
       "  {'street': '',\n",
       "   'adminArea6': '',\n",
       "   'adminArea6Type': 'Neighborhood',\n",
       "   'adminArea5': '',\n",
       "   'adminArea5Type': 'City',\n",
       "   'adminArea4': '',\n",
       "   'adminArea4Type': 'County',\n",
       "   'adminArea3': '',\n",
       "   'adminArea3Type': 'State',\n",
       "   'adminArea1': 'TH',\n",
       "   'adminArea1Type': 'Country',\n",
       "   'postalCode': '',\n",
       "   'geocodeQualityCode': 'A1XAX',\n",
       "   'geocodeQuality': 'COUNTRY',\n",
       "   'dragPoint': False,\n",
       "   'sideOfStreet': 'N',\n",
       "   'linkId': '282934956',\n",
       "   'unknownInput': '',\n",
       "   'type': 's',\n",
       "   'latLng': {'lat': 15.0086, 'lng': 100.955704},\n",
       "   'displayLatLng': {'lat': 15.0086, 'lng': 100.955704}}]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MapQuest Geocode service.  More info: https://developer.mapquest.com/documentation/geocoding-api/\n",
    "mapquest_address_url=\"https://www.mapquestapi.com/geocoding/v1/address?key=AuqdPFEWYhm7rZRN5hX5HeWSKgaO2u7d&location=\"\n",
    "def geocode(text):\n",
    "    req = requests.get(mapquest_address_url+text)\n",
    "    jsn = req.json()\n",
    "    loc = jsn[\"results\"][0][\"locations\"][0]\n",
    "    return loc\n",
    "\n",
    "# Send batches to the MapQuest Geocode API in up to 100 locations at a time\n",
    "# Saves on API monthly rate (15000 calls per month in the free tier)\n",
    "#mapquest_batch_url=\"http://www.mapquestapi.com/geocoding/v1/batch?&inFormat=json&outFormat=json&key=AuqdPFEWYhm7rZRN5hX5HeWSKgaO2u7d\"\n",
    "def geocode_batch(batch):\n",
    "    mapquest_batch_url=\"http://www.mapquestapi.com/geocoding/v1/batch?key=AuqdPFEWYhm7rZRN5hX5HeWSKgaO2u7d&maxResults=1&thumbMaps=false\"\n",
    "    request_locations = []\n",
    "    reverse_lookup = {}\n",
    "    response = {}\n",
    "    \n",
    "    #Create reverse lookup table for the API response\n",
    "    for movie in batch:\n",
    "        movie_id = movie[\"id\"]\n",
    "        location = movie[\"location\"]\n",
    "        if movie_id not in response:\n",
    "            response[movie_id] = []\n",
    "        if location not in reverse_lookup:\n",
    "            reverse_lookup[location] = []\n",
    "        reverse_lookup[location].append(movie_id)\n",
    "        mapquest_batch_url += \"&location=\" + location\n",
    "    print(mapquest_batch_url)\n",
    "    req = requests.get(mapquest_batch_url)\n",
    "    jsn = req.json()\n",
    "\n",
    "    # Map the API location results to the movie IDs\n",
    "    for result in jsn[\"results\"]:\n",
    "        if \"providedLocation\" in result and \"locations\" in result and len(result[\"locations\"]):\n",
    "            provided = result[\"providedLocation\"][\"location\"]\n",
    "            location = result[\"locations\"][0]\n",
    "            if location[\"geocodeQuality\"] != \"COUNTRY\" or location[\"adminArea1\"] != \"US\":\n",
    "                if provided in reverse_lookup:\n",
    "                    for movie_id in reverse_lookup[provided]:\n",
    "                        response[movie_id].append(location)\n",
    "                else:\n",
    "                    print(\"Not found\",provided)\n",
    "                \n",
    "    return response\n",
    "\n",
    "enriched_movie_ids = geocode_batch([\n",
    "    {\"id\":123,\"location\":\"New York\"},\n",
    "    {\"id\":123,\"location\":\"Manhattan\"},\n",
    "    {\"id\":123,\"location\":\"Thailand\"},\n",
    "])\n",
    "\n",
    "enriched_movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#us-map-with-latitude-longitude-united-states-latitude-longitude.jpg\n",
    "\n",
    "#Disambiguate to the nearest lat/lng whole numbers:\n",
    "def near(loc):\n",
    "    latlng = loc[\"latLng\"]\n",
    "    return round(latlng[\"lat\"]),round(latlng[\"lng\"])\n",
    "\n",
    "#Normalize to City|State|Country:\n",
    "def norm(loc):\n",
    "    loctypes = {\"City\":\"\",\"State\":\"\",\"Country\":\"\"}\n",
    "    location = None\n",
    "    for i in range(8):\n",
    "        aai = \"adminArea\"+str(i)\n",
    "        aat = aai+\"Type\"\n",
    "        if aat in loc.keys() and loc[aat] in loctypes.keys():\n",
    "            loctypes[loc[aat]] = aai\n",
    "    for typ in loctypes.keys():\n",
    "        fld = loctypes[typ]\n",
    "        if fld in loc.keys() and len(loc[fld]):\n",
    "            if not location:\n",
    "                location = loc[fld]\n",
    "            else:\n",
    "                location += \"|\" + loc[fld]\n",
    "    if not location:\n",
    "        location = \"_UNKNOWN_\"\n",
    "    return location.replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get entities with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New', 'York', 'NY', 'Thailand']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_independent_locations(text):\n",
    "    doc = nlp(text)\n",
    "    locs = []\n",
    "    #Fun fact, \"GPE\" means Geo-Political Entity\n",
    "    for gpe in filter(lambda w: w.ent_type_ in ['GPE'], doc):\n",
    "        locs.append(gpe.text)\n",
    "    return locs\n",
    "extract_independent_locations(\"I left the New York, NY to visit Thailand.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich a title with a location using SpaCy and Mapquest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lat': 41, 'lng': -74, 'location': 'New_York|NY|US'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def enrich_content_locations(text):\n",
    "    enrichment = {\"lat\":None,\"lng\":None,\"location\":None}\n",
    "    entities = extract_independent_locations(text)\n",
    "    if len(entities):\n",
    "        #found a location - look it up in mapquest and disambiguate\n",
    "        entity = \" \".join(entities)\n",
    "        geoloc = geocode(entity)\n",
    "        if geoloc:\n",
    "            latlng = near(geoloc)\n",
    "            location = norm(geoloc)\n",
    "            if latlng and len(latlng)==2:\n",
    "                # It's a valid location! \n",
    "                # ...add the filter query and remove the text from the query:\n",
    "                enrichment[\"lat\"] = latlng[0]\n",
    "                enrichment[\"lng\"] = latlng[1]\n",
    "            if location:\n",
    "                enrichment[\"location\"] = location\n",
    "    return enrichment\n",
    "enrich_content_location(\"Kevin alone in NYC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate through the movies\n",
    "def rawTmdbMovies(filename):\n",
    "    return json.load(open(filename))\n",
    "\n",
    "\n",
    "def writeTmdmMovies(rawMoviesJson, path):\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(rawMoviesJson, f)\n",
    "\n",
    "def tmdbMovies(filename):\n",
    "    tmdbMovies = rawTmdbMovies(filename)\n",
    "    for movieId, tmdbMovie in tmdbMovies.items():\n",
    "        yield (movieId, tmdbMovie)\n",
    "\n",
    "\n",
    "def indexableMovies(filename=\"../tmdb.json\"):\n",
    "    \"\"\" Generates TMDB movies, similar to how ES Bulk indexing\n",
    "        uses a generator to generate bulk index/update actions \"\"\"\n",
    "    for movieId, tmdbMovie in tmdbMovies(filename):\n",
    "        try:\n",
    "            releaseDate = None\n",
    "            if 'release_date' in tmdbMovie and len(tmdbMovie['release_date']) > 0:\n",
    "                releaseDate = tmdbMovie['release_date'] + 'T00:00:00Z'\n",
    "\n",
    "            if 'title_entities' in tmdbMovie and len(tmdbMovie['title_entities']) > 0:                \n",
    "                yield {'id': movieId,\n",
    "                       'title': tmdbMovie['title'],\n",
    "                       'overview': tmdbMovie['overview'],\n",
    "                       'tagline': tmdbMovie['tagline'],\n",
    "                       'directors': [director['name'] for director in tmdbMovie['directors']],\n",
    "                       'cast': [castMember['name'] for castMember in tmdbMovie['cast']],\n",
    "                       'genres': [genre['name'] for genre in tmdbMovie['genres']],\n",
    "                       'release_date': releaseDate,\n",
    "                       'vote_average': tmdbMovie['vote_average'] if 'vote_average' in tmdbMovie else None,\n",
    "                       'vote_count': int(tmdbMovie['vote_count']) if 'vote_count' in tmdbMovie else None,\n",
    "                       'title_entities': tmdbMovie['title_entities'] if 'title_entities' in tmdbMovie else [],                   \n",
    "                       'overview_entities': tmdbMovie['overview_entities'] if 'overview_entities' in tmdbMovie else [],\n",
    "                       }\n",
    "            else:\n",
    "                yield {'id': movieId,\n",
    "                       'title': tmdbMovie['title'],\n",
    "                       'overview': tmdbMovie['overview'],\n",
    "                       'tagline': tmdbMovie['tagline'],\n",
    "                       'directors': [director['name'] for director in tmdbMovie['directors']],\n",
    "                       'cast': [castMember['name'] for castMember in tmdbMovie['cast']],\n",
    "                       'genres': [genre['name'] for genre in tmdbMovie['genres']],\n",
    "                       'release_date': releaseDate,\n",
    "                       'vote_average': tmdbMovie['vote_average'] if 'vote_average' in tmdbMovie else None,\n",
    "                       'vote_count': int(tmdbMovie['vote_count']) if 'vote_count' in tmdbMovie else None,\n",
    "                       }\n",
    "        except KeyError as k: # Ignore any movies missing these attributes\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'title_entities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-94f74ce210b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmdb_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0menrich_movies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-94f74ce210b2>\u001b[0m in \u001b[0;36menrich_movies\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mmovie\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title_entities\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mmovie\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"overview_entities\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle_entities\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverview_entities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;31m#found a location - add it to the mapquest batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'title_entities' is not defined"
     ]
    }
   ],
   "source": [
    "def enrich_movie():\n",
    "    geoloc = geocode(entity)\n",
    "    if geoloc:\n",
    "        latlng = near(geoloc)\n",
    "        location = norm(geoloc)\n",
    "        if latlng and len(latlng)==2:\n",
    "            # It's a valid location! \n",
    "            # ...add the filter query and remove the text from the query:\n",
    "            enrichment[\"lat\"] = latlng[0]\n",
    "            enrichment[\"lng\"] = latlng[1]\n",
    "        if location:\n",
    "            enrichment[\"location\"] = location\n",
    "    return enrichment\n",
    "\n",
    "def entitize_movies():\n",
    "    total = 0\n",
    "    batch = []\n",
    "    movies = {}\n",
    "    tmdb_spacy = []\n",
    "    tmdb_json = []\n",
    "    for movie in indexableMovies():\n",
    "        title_entities = extract_independent_locations(movie[\"title\"])\n",
    "        overview_entities = extract_independent_locations(movie[\"overview\"])\n",
    "        movie[\"title_entities\"] = title_entities\n",
    "        movie[\"overview_entities\"] = overview_entities\n",
    "        tmdb_spacy.append(movie)\n",
    "    writeTmdmMovies(tmdb_spacy,'../tmdb_spacy.json')\n",
    "    \n",
    "\n",
    "def enrich_movies():\n",
    "    total = 0\n",
    "    batch = []\n",
    "    movies = {}\n",
    "    tmdb_spacy = []\n",
    "    tmdb_enriched = []\n",
    "    for movie in indexableMovies():\n",
    "        overview_entities = movie[\"overview_entities\"]\n",
    "        title_entities = movie[\"title_entities\"]\n",
    "        if len(title_entities) or len(overview_entities):\n",
    "            #found a location - add it to the mapquest batch\n",
    "            movies[\"id\"] = movie\n",
    "            for entity in title_entities:\n",
    "                batch.append({\"id\":movie[\"id\"],\"location\":entity})\n",
    "                total +=1\n",
    "            for entity in overview_entities:\n",
    "                batch.append({\"id\":movie[\"id\"],\"location\":entity})\n",
    "                total += 1\n",
    "            if (total>=98):\n",
    "                geocodes = geocode_batch(batch)\n",
    "                if \"location\" not in movie:\n",
    "                    movie[\"location\"] = []\n",
    "                for movie_id in geocodes.keys():\n",
    "                    latlon = movie\n",
    "                    movie[\"location\"].append()\n",
    "                index_movies(enriched)\n",
    "                #locations = geocode_batch(batch)\n",
    "                batch = []\n",
    "                movies = {}\n",
    "                total = 0\n",
    "        movie.pop('title_entities', None)\n",
    "        movie.pop('overview_entities', None)\n",
    "        tmdb_enriched.append(movie)\n",
    "        \n",
    "    writeTmdmMovies(tmdb_enriched,'../tmdb_enriched.json')\n",
    "    \n",
    "enrich_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solr Client\n",
    "solr = pysolr.Solr('http://localhost:8983/solr/tmdb')\n",
    "\n",
    "#Print the Title, Release Date, and Overview from TMDB\n",
    "def printresults(res):\n",
    "    for r in res:\n",
    "        print('\\n---')\n",
    "        print('\\n\\t'.join([r[\"title\"][0],r[\"lat\"],r[\"lng\"],r[\"overview\"][0]]))\n",
    "\n",
    "def solrquery(q):\n",
    "    return \"title_en:(\"+q+\")^1.2 overview_en:(\"+q+\")\"\n",
    "        \n",
    "#Enrich and Search a text query\n",
    "def search(query):\n",
    "    enriched = enrich_query_location(query)\n",
    "    q = solrquery(enriched[\"q\"])\n",
    "    print(\"Searching for `\" + query + \"` ...\")\n",
    "    print(\"  q = \" + q)\n",
    "    if \"fq\" in enriched and isinstance(enriched[\"fq\"], str):\n",
    "        fq = enriched[\"fq\"]\n",
    "        print(\"  fq = \" + fq)\n",
    "        res = solr.search(q=q,fq=fq,fl=\"title,overview,lat,lng\",rows=3)\n",
    "    else:\n",
    "        print(\"  ...no enrichments\")\n",
    "        res = solr.search(q=q,fl=\"title,overview,release_date\",rows=3)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try it with some good examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'printresults' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aef963d90df9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprintresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"harry potter last 5 years\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'printresults' is not defined"
     ]
    }
   ],
   "source": [
    "printresults(search(\"harry potter last 5 years\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for `indiana jones 1/1/1980 to 12/31/1987` ...\n",
      "  q = title_en:(indiana jones )^1.2 overview_en:(indiana jones )\n",
      "  fq = release_date:[1980-01-01T00:00:00Z TO 1988-01-01T00:00:00Z]\n",
      "\n",
      "---\n",
      "Indiana Jones and the Temple of Doom\n",
      "\t1984-05-23T00:00:00Z\n",
      "\tAfter arriving in India, Indiana Jones is asked by a desperate village to find a mystical stone. He agrees – and stumbles upon a secret cult plotting a terrible plan in the catacombs of an ancient palace.\n",
      "\n",
      "---\n",
      "Raiders of the Lost Ark\n",
      "\t1981-06-12T00:00:00Z\n",
      "\tWhen Dr. Indiana Jones – the tweed-suited professor who just happens to be a celebrated archaeologist – is hired by the government to locate the legendary Ark of the Covenant, he finds himself up against the entire Nazi regime.\n",
      "\n",
      "---\n",
      "Guyana Tragedy: The Story of Jim Jones\n",
      "\t1980-04-15T00:00:00Z\n",
      "\tThe story of the Peoples Temple cult led by Jim Jones and the events leading up to one of the largest mass suicides in history.\n"
     ]
    }
   ],
   "source": [
    "printresults(search(\"indiana jones 1/1/1980 to 12/31/1987\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for `harry potter goblet` ...\n",
      "  q = title_en:(harry potter goblet)^1.2 overview_en:(harry potter goblet)\n",
      "  ...no enrichments\n",
      "\n",
      "---\n",
      "Harry Potter and the Goblet of Fire\n",
      "\t2005-11-05T00:00:00Z\n",
      "\tHarry starts his fourth year at Hogwarts, competes in the treacherous Triwizard Tournament and faces the evil Lord Voldemort. Ron and Hermione help Harry manage the pressure – but Voldemort lurks, awaiting his chance to destroy Harry and all that he stands for.\n",
      "\n",
      "---\n",
      "Harry Potter and the Philosopher's Stone\n",
      "\t2001-11-16T00:00:00Z\n",
      "\tHarry Potter has lived under the stairs at his aunt and uncle's house his whole life. But on his 11th birthday, he learns he's a powerful wizard -- with a place waiting for him at the Hogwarts School of Witchcraft and Wizardry. As he learns to harness his newfound powers with the help of the school's kindly headmaster, Harry uncovers the truth about his parents' deaths -- and about the villain who's to blame.\n",
      "\n",
      "---\n",
      "A Very Potter Musical\n",
      "\t2009-04-09T00:00:00Z\n",
      "\tIn April 2009, a group of University of Michigan students (Team StarKid) performed what was renamed \"A Very Potter Musical\", a two act musical parody that featured major elements from all seven Harry Potter books and an original score.\n"
     ]
    }
   ],
   "source": [
    "printresults(search(\"harry potter goblet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
